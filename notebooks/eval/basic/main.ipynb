{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/run/media/sahilsasane/Disk_1/Sahil/TMDC/test_repo/travel-agent/notebooks\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pretty_print import pretty_print_messages\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-definite-invite-58\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8943081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "tool_node = ToolNode(tools)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "# llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "model = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5c2853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search (call_o5NTwUdDgmA7yKXzw47ivUfY)\n",
      " Call ID: call_o5NTwUdDgmA7yKXzw47ivUfY\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search\n",
      "\n",
      "It's 60 degrees and foggy.\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in San Francisco is 60 degrees and foggy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from langfuse import Langfuse\n",
    "# from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# langfuse = Langfuse(\n",
    "#     public_key=\"pk-lf-c7be1653-c7b1-4136-90e9-6132b375e823\",\n",
    "#     secret_key=\"sk-lf-dc2be4ce-811a-46b5-a385-7bbe1ab307b8\",\n",
    "#     host=\"http://localhost:3000\",\n",
    "# )\n",
    "\n",
    "# langfuse_handler = CallbackHandler()\n",
    "\n",
    "# # <Your Langchain code here>\n",
    "\n",
    "# # Add handler to run/invoke/call/chat\n",
    "\n",
    "# # chain.invoke({\"input\": \"<user_input>\"}, config={\"callbacks\": [langfuse_handler]})\n",
    "# state = await app.ainvoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"whats the weather in sf?\"}]},\n",
    "#     config={\"callbacks\": [langfuse_handler]},\n",
    "# )\n",
    "\n",
    "# for chunk in app.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": \"whats the weather in sf?\",\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "#     config={\"callbacks\": [langfuse_handler]},\n",
    "#     debug=False,\n",
    "# ):\n",
    "#     pretty_print_messages(chunk, last_message=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aafe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "questions = [\n",
    "    \"what's the weather in sf\",\n",
    "    \"whats the weather in san fran\",\n",
    "    \"whats the weather in tangier\",\n",
    "]\n",
    "answers = [\n",
    "    \"It's 60 degrees and foggy.\",\n",
    "    \"It's 60 degrees and foggy.\",\n",
    "    \"It's 90 degrees and sunny.\",\n",
    "]\n",
    "\n",
    "ls_client = Client()\n",
    "\n",
    "dataset = ls_client.create_dataset(\"weather agent\")\n",
    "ls_client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    inputs=[\n",
    "        {\"question\": \"what's the weather in sf\"},\n",
    "        {\"question\": \"whats the weather in san fran\"},\n",
    "        {\"question\": \"whats the weather in tangier\"},\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"answer\": \"It's 60 degrees and foggy.\"},\n",
    "        {\"answer\": \"It's 60 degrees and foggy.\"},\n",
    "        {\"answer\": \"It's 90 degrees and sunny.\"},\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9f0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_llm = llm\n",
    "\n",
    "\n",
    "async def correct(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    instructions = (\n",
    "        \"Given an actual answer and an expected answer, determine whether\"\n",
    "        \" the actual answer contains all of the information in the\"\n",
    "        \" expected answer. Respond with 'CORRECT' if the actual answer\"\n",
    "        \" does contain all of the expected information and 'INCORRECT'\"\n",
    "        \" otherwise. Do not include anything else in your response.\"\n",
    "    )\n",
    "\n",
    "    actual_answer = outputs[\"messages\"][-1].content\n",
    "    expected_answer = reference_outputs[\"answer\"]\n",
    "    user_msg = f\"ACTUAL ANSWER: {actual_answer}\\n\\nEXPECTED ANSWER: {expected_answer}\"\n",
    "    response = await judge_llm.ainvoke(\n",
    "        [{\"role\": \"system\", \"content\": instructions}, {\"role\": \"user\", \"content\": user_msg}]\n",
    "    )\n",
    "    return response.content.upper() == \"CORRECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a1bd2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'dear-place-15' at:\n",
      "https://smith.langchain.com/o/dd73791d-a177-49ce-88d8-6d38e552760c/datasets/7cf133cd-bda0-43f7-b64f-23937057e460/compare?selectedSessions=6e813bc3-fc17-4612-bd77-9bff01475b91\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith import aevaluate\n",
    "\n",
    "\n",
    "def example_to_state(inputs: dict) -> dict:\n",
    "    # print(inputs)\n",
    "    return {\"messages\": [{\"role\": \"user\", \"content\": inputs[\"question\"]}]}\n",
    "\n",
    "\n",
    "target = example_to_state | app\n",
    "\n",
    "experiment_results = await aevaluate(\n",
    "    target,\n",
    "    data=\"weather agent\",\n",
    "    evaluators=[correct],\n",
    "    max_concurrency=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2e65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'dependable-animal-5' at:\n",
      "https://smith.langchain.com/o/dd73791d-a177-49ce-88d8-6d38e552760c/datasets/7cf133cd-bda0-43f7-b64f-23937057e460/compare?selectedSessions=c31d1a3c-24a3-4c17-aca9-27d89d6b5bc0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'whats the weather in tangier'}\n",
      "{'question': 'whats the weather in san fran'}\n",
      "{'question': \"what's the weather in sf\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference_outputs {'answer': \"It's 60 degrees and foggy.\"}\n",
      "outputs {'messages': [HumanMessage(content='whats the weather in san fran', additional_kwargs={}, response_metadata={}, id='5c99bb2d-07bd-4c74-9099-39970ecec9b6'), AIMessage(content='<function=search{\"query\": \"San Francisco weather\"}</function>', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 215, 'total_tokens': 230, 'completion_time': 0.079605657, 'prompt_time': 0.014459086, 'queue_time': 0.052128954000000005, 'total_time': 0.094064743}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None}, id='run--ca889378-12ab-45e3-a216-e753f7d7cf4d-0', usage_metadata={'input_tokens': 215, 'output_tokens': 15, 'total_tokens': 230})]}\n",
      "reference_outputs {'answer': \"It's 90 degrees and sunny.\"}\n",
      "outputs {'messages': [HumanMessage(content='whats the weather in tangier', additional_kwargs={}, response_metadata={}, id='1f1af0bf-39b5-41eb-a4b9-2b87c056038c'), AIMessage(content='<function=search{\"query\": \"Tangier weather\"}</function>', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 215, 'total_tokens': 231, 'completion_time': 0.244340672, 'prompt_time': 0.013386129, 'queue_time': 0.053304947000000005, 'total_time': 0.257726801}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None}, id='run--ea63c901-1df4-4658-922d-2b604dcdcd8d-0', usage_metadata={'input_tokens': 215, 'output_tokens': 16, 'total_tokens': 231})]}\n",
      "reference_outputs {'answer': \"It's 60 degrees and foggy.\"}\n",
      "outputs {'messages': [HumanMessage(content=\"what's the weather in sf\", additional_kwargs={}, response_metadata={}, id='4f9bd24a-fd3c-48a3-aa64-6cc712129850'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'wgqjqy7xx', 'function': {'arguments': '{\"query\":\"San Francisco weather today\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 214, 'total_tokens': 230, 'completion_time': 0.070587512, 'prompt_time': 0.014596565, 'queue_time': 0.052046361000000006, 'total_time': 0.085184077}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a2be33b7-bf9f-4305-995f-096ea7a604a6-0', tool_calls=[{'name': 'search', 'args': {'query': 'San Francisco weather today'}, 'id': 'wgqjqy7xx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 214, 'output_tokens': 16, 'total_tokens': 230}), ToolMessage(content=\"It's 60 degrees and foggy.\", name='search', id='66551f90-999c-4796-a396-e48dc19e71c6', tool_call_id='wgqjqy7xx'), AIMessage(content=\"I'm glad I could help you with the weather. Is there anything else I can help you with?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 249, 'total_tokens': 271, 'completion_time': 0.081280796, 'prompt_time': 0.016069066, 'queue_time': 0.06285322400000001, 'total_time': 0.097349862}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run--bca60890-b695-4cfe-b849-f63d72c8a148-0', usage_metadata={'input_tokens': 249, 'output_tokens': 22, 'total_tokens': 271})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def right_tool(outputs: dict) -> bool:\n",
    "    tool_calls = outputs[\"messages\"][1].tool_calls\n",
    "    return bool(tool_calls and tool_calls[0][\"name\"] == \"search\")\n",
    "\n",
    "\n",
    "experiment_results = await aevaluate(\n",
    "    target,\n",
    "    data=\"weather agent\",\n",
    "    evaluators=[correct, right_tool],\n",
    "    # max_concurrency=4,  # optional\n",
    "    # experiment_prefix=\"claude-3.5-baseline\",  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb692bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def right_tool_from_run(run: Run, example: Example) -> dict:\n",
    "    # Get documents and answer\n",
    "    first_model_run = next(run for run in run.child_runs if run.name == \"agent\")\n",
    "    tool_calls = first_model_run.outputs[\"messages\"][-1].tool_calls\n",
    "    right_tool = bool(tool_calls and tool_calls[0][\"name\"] == \"search\")\n",
    "    return {\"key\": \"right_tool\", \"value\": right_tool}\n",
    "\n",
    "\n",
    "experiment_results = await aevaluate(\n",
    "    target,\n",
    "    data=\"weather agent\",\n",
    "    evaluators=[correct, right_tool_from_run],\n",
    "    # max_concurrency=4,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
